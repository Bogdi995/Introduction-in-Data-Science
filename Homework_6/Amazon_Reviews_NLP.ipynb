{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7f2558",
   "metadata": {},
   "source": [
    "# Techniken in MachineLearning - NLP (Natural Language Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0de9e5",
   "metadata": {},
   "source": [
    "Datensatz [Amazon Commerce reviews set Data Set](https://archive.ics.uci.edu/ml/datasets/Amazon+Commerce+reviews+set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0835e4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: regex in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from seaborn) (3.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from seaborn) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from seaborn) (1.18.5)\n",
      "Requirement already satisfied: pandas>=0.22.0 in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from seaborn) (1.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from pandas>=0.22.0->seaborn) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bogdi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=2.1.2->seaborn) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aea1fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bogdi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bogdi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import scipy\n",
    "import pandas\n",
    "import sklearn\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from typing import List, Dict, Union\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0a2be",
   "metadata": {},
   "source": [
    "### Amazon Fine Foods Reviews\n",
    "##### Quelle:\n",
    "J. McAuley und J. Leskovec. Von Amateuren zu Kennern: Gestaltung der Entwicklung von Nutzerkompetenz durch Online-Bewertungen. WWW, 2013.\n",
    "\n",
    "##### Informationsdatensatz:\n",
    "Dieser Datensatz besteht aus Rezensionen von Feinkostprodukten auf Amazon. Die Daten erstrecken sich über mehr als 10 Jahre, einschließlich aller ~500.000 Rezensionen bis Oktober 2012. Die Rezensionen enthalten Produkt- und Benutzerinformationen, Bewertungen und eine reine Textrezension. Wir haben auch Rezensionen aus allen anderen Amazon-Kategorien.\n",
    "\n",
    "##### Informationen zu den Attributen:\n",
    "Anzahl der Rezensionen: 568,454 <br>\n",
    "Anzahl der Nutzer: 256.059 <br>\n",
    "Anzahl der Produkte: 74,258 <br>\n",
    "Nutzer mit > 50 Bewertungen: 260 <br>\n",
    "Mittlere Anzahl von Wörtern pro Bewertung: 56 <br>\n",
    "Dauer des Zeitraums: Oktober 1999 - Oktober 2012 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37fe4f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Form des Datenrahmens ist: (568411, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductId          UserId                      ProfileName  \\\n",
       "Id                                                                \n",
       "1   B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "2   B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "3   B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "4   B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "5   B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "    HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "Id                                                                    \n",
       "1                      1                       1      5  1303862400   \n",
       "2                      0                       0      1  1346976000   \n",
       "3                      1                       1      4  1219017600   \n",
       "4                      3                       3      2  1307923200   \n",
       "5                      0                       0      5  1350777600   \n",
       "\n",
       "                  Summary                                               Text  \n",
       "Id                                                                            \n",
       "1   Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "2       Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "3   \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "4          Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "5             Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df:object = pd.read_csv('./Reviews.csv', index_col=0)\n",
    "df = df.dropna()\n",
    "print(f'Die Form des Datenrahmens ist: {df.shape}')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b60571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Datenrahmen hat nach dem Entfernen der doppelten Zeilen folgende Form: (393919, 9)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(subset={'UserId', 'ProfileName', 'Time', 'Text'}, inplace=True)\n",
    "print(f'Der Datenrahmen hat nach dem Entfernen der doppelten Zeilen folgende Form: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0279694d",
   "metadata": {},
   "source": [
    "Grafik, die zeigt, welche Kundenrezensionen die Mehrheit sind. <br>\n",
    "Es ist zu erkennen, dass die Bewertungen mit der höchsten Punktzahl (ca. 250000) überwiegen. <br>\n",
    "Wir können die Bewertungen entsprechend ihrer Punktzahl wie folgt in Kategorien einteilen: <br>\n",
    "Punktzahl > 3 -> positive Bewertung <br>\n",
    "Punktzahl = 3 -> neutrale Bewertung <br>\n",
    "Punktzahl < 3 -> negative Bewertung <br>\n",
    "Auch hier überwiegen die positiven Bewertungen (ca. 310000), aber auch die negativen Bewertungen sind nicht zu vernachlässigen (ca. 70000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b624dc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAAG2CAYAAADP8NdHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df7xldV3v8ddbUCT5IT9GUgYdEqwAE3Maf95CMSA0wdIcu8VUJF3T/JGV2L03SC837VqUt7QwJn4YChfrSiriCGJXRWAwAgGJSUiQX4PDL0Wogc/9Y31P7jmeOXPmy+zzY+b1fDz246z9Xev7Xd+1Z89+n+93rb1OqgpJkrR5HjPXHZAkaSEyQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDgaoNEuSXJPkkLnuR48kJyb50Bzs91tJfmC29yvNhAGqsUtycZK7k+ww133ZHEkOSXJxR72LkzzYPvwnHs+vqgOrarPbm8H+Tkvyb5P295otvZ9p9n9Ikkfafu9Pcn2SX94SbVfVTlX1tS3R1uZIsiRJjbyedyT5eJKf3Iw2finJ58fZz9ncj76XAaqxSrIE+E9AAa+Y087Mrje2D/+JxyVj3t8fTtrf2WPe32S3VtVOwC7AW4EPJvnBWe7DODyxHdezgFXA3yX5pbntkuYLA1TjdgzwJeA0YMXoijZyen+S89tv+V9I8v1J/qSNWL+a5Nkj2x+f5F/aKOfaJK8cWfdPk0ZgNTFdmuQVbfr0njY6/OGRejcl+a0kVyW5N8nZSR4/+SAyODnJnW27q5IctDkvRNvXS9vyiUnOSXJGO55rkiwd2fYpST6aZG2SG5O8aXP2NdLO65KsSbIuyXlJnjKy7gVJLm/Hc3mSF4ys2zfJ51rfVgF7zmR/NfgksA74kdbWY0b+7b7Zjnv3tu5TSd44qc//lORn2nIl2a8t75DkvUm+3kaEf5Fkx7buc0l+ti2/qNU7sj1/aZIr2/J+bdt7k9yVZEa/aFTV7VX1p8CJwHuSPKa1N+V7sr3H/gJ4fns/3tPKX5bkH5Pcl+TmJCeOHPfjk3yovUb3tH+Tvdq6XZOcmuS2JN9I8j+SbLex/Wh2GKAat2OAv2mPwyc+EEb8HPDfGD6gHwIuAb7cnp8L/PHItv/CMJrdFfh94ENJngxQVc+aGH0BvwlcD3w5yTOADwNvARYBnwT+PsnjJvXhCGBfhg/9X2ptXlxVh7RtDgN+HHgG8ETgNcA3e1+U5hXAR1p75wF/BkPgAH8P/BOwN3Ao8JYkh29O40leAvwBw/E9GfjXtj9agH0CeB+wB8Pr/Ikke7TqZwFXMPw7vItJv/xMs8/HJHlFq7emFb8JOBr4CeApwN3An4/s57Uj9Q8Antb6Ntl7GF7/g4H9GF6b32vrPgcc0pZ/HPha29/E88+15XcBnwZ2AxYD/3smxzXib4EnAROj6ynfk1V1HfBfgEva+/KJbftvM/yfeCLwMuD1SY5u61a0dvZh+Df5L8B32rrTgfXtuJ/N8H781Wn2o9lQVT58jOUBvAj4d2DP9vyrwFtH1p8GfHDk+W8A1408fyZwzzTtXwkcNcU+7wSe0Z7/d+CckfWPAb4BHNKe3wT8wsj6PwT+Yop9vQT4Z+B5wGM2cdwXAw8A97THl0f29dK2fCLwmZE6BwDfacvPBb4+qc13AH+9kf2dBjw4sr+7WvmpDFO7E9vt1P49lgC/CFw2qZ1LGH55eCrDh/UTRtadBXxoI/s/BHik7fsh4GHgLSPrrwMOHXn+5NaP7YGdGULlaW3dScDKkW2LITTStnv6yLrnAze25UOBq9ryp4BfBb7Unn8O+Jm2fAZwCrB4E/+GS9q+t59U/vhW/sJNvSfba/n5TeznT4CT2/KvAF8EfmTSNnu113XHkbLXAp+d6X58jOfhCFTjtAL4dFXd1Z6fxfeOZO4YWf7OFM93mniS5JgkV7bprXuAgxiZWkyyD3AOsKKq/rkVP4Vh5AVAVT0C3Mwweplw+8jyA6P7HKl3EcMI8c+BO5KckmSXjR048KaqemJ7/OhGtpm838cn2Z5hBPaUieNsx/q7DB+kG/Pekf1NvCaTj/1bDKPmvSeva/51ZN3dVfXtSeumc2sNo59dGEa1LxlZ9zSGc4cTx3IdQ8juVVX3M4w2l7dtlzPMVky2CPg+4IqRdj7VymEI/2e0GY6DGYJynyR7AsuAf2jb/Q5DGF/Wps1/ZRPHNdnE+2YdbPo9OVmS5yb5bJuav5dh9Dix/ZnABcBHktya5A+TPJbh9XsscNvIfv6SYSSsOWSAaizauamfA34iye1Jbme4uORZSZ7V0d7TgA8CbwT2aB/WX2H4MJzY3/8F/qSqzh+peivDB9BEO2GYIvvG5vahqt5XVc8BDmSYSvztzW1jhm5mGFk9ceSxc1UduZntTD72JzBMDX5j8rrmqW3dbcBubfvRdZtUVQ8BbweeOTI1eTPwU5OO5/FVNfFv8GHgtUmeD+wIfHaKpu9i+IXqwJE2dq1hyp6qeoBhyvnNwFeq6t8YRnO/CfzLxC9xNZzLfF1VPQX4NeD9E+dYZ+iVDDMc12/qPckwUp3sLIbp+n2qaleG85dpffv3qvr9qjoAeAHwcobp3psZRqB7jhz7LlV14DT70SwwQDUuRzOMMg5gGBEcDPww8P8YPhQ21xMYPijWAmT4msToRTwrga9W1R9OqncO8LIkh7bf5t/G8GH0xc3ZeZIfa6OHxzJMJT7IcHzjcBlwX5K3J9mxXSxyUJIf28x2zgJ+OcnBGb5C9D+BS6vqJoZzwc9I8vNJts/wtZcDgI9X1b8Cq4HfT/K4JC8CfnqmO23h9Ud89/zkXwAntcAhyaIkR41U+SRDmL8TOLvNEkxu8xGGsDo5yZNaO3tPOi/8OYYwmzjfefGk5yR5dZLF7endDO+pTf47Jtkrw8VOJwDvaP3Z1HvyDmDxpPPtOwPrqurBJMuAnx/Zx4uTPDPJdsB9DNPcD1fVbQznbf8oyS7tPPPTk/zENPvRLDBANS4rGM7Zfb391n97Vd3OMA36n9tU5YxV1bUMH8qXMHxgPBP4wsgmy4FXZsMrcf9TVV0P/ALDxSJ3MQTBT7cP+c2xC8MH+N0M05nfBN67mW3MSFU9zNDPg4EbGfr9VwwXmGxOOxcynAP+KMOo8um0qdKq+ibDCOdtDMfyO8DLR6bbf57hXOw6htA4YzMPYyXw1CQ/Dfwpw6jr00nuZ7gq+7kj/XyI4eKclzKE/sa8neHCpC8luQ/4DN+9mAeGoNyZ707XTn4O8GPApUm+1fr05qq6cZp93pPk28DVwJHAq6tqZev3pt6TFwHXALcnmXhdfx14Z3sdfo/hF7wJ389w4dx9DNPcnwMmbl5xDPA44FqG9+C5DOeSN7YfzYJUOfqXJGlzOQKVJKmDASpJUgcDVJKkDgaoJEkdDFBJkjps1lcJtmZ77rlnLVmyZK67IUmaR6644oq7qmrRVOsM0GbJkiWsXr16rrshSZpHkmz0NpZO4UqS1MEAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDgaoJEkdDFBJkjqMLUCT7JPks0muS3JNkje38hOTfCPJle1x5EiddyRZk+T6JIePlD8nydVt3fuSpJXvkOTsVn5pkiUjdVYkuaE9VozrOCVJ26Zx/j3Q9cDbqurLSXYGrkiyqq07uareO7pxkgOA5cCBwFOAzyR5RlU9DHwAOA74EvBJ4AjgfOBY4O6q2i/JcuA9wGuS7A6cACwFqu37vKq6e4zHK0nahowtQKvqNuC2tnx/kuuAvaepchTwkap6CLgxyRpgWZKbgF2q6hKAJGcARzME6FHAia3+ucCftdHp4cCqqlrX6qxiCN0Pb9GDnMaS4z8xW7vabDe9+2Vz3QVJWvBm5Rxom1p9NnBpK3pjkquSrEyyWyvbG7h5pNotrWzvtjy5fIM6VbUeuBfYY5q2JvfruCSrk6xeu3Zt9/FJkrY9Yw/QJDsBHwXeUlX3MUzHPh04mGGE+kcTm05RvaYp763z3YKqU6pqaVUtXbRo0bTHIUnSqLEGaJLHMoTn31TV3wJU1R1V9XBVPQJ8EFjWNr8F2Gek+mLg1la+eIryDeok2R7YFVg3TVuSJG0R47wKN8CpwHVV9ccj5U8e2eyVwFfa8nnA8nZl7b7A/sBl7Vzq/Ume19o8BvjYSJ2JK2xfBVxUVQVcAByWZLc2RXxYK5MkaYsY51W4LwR+Ebg6yZWt7HeB1yY5mGFK9Sbg1wCq6pok5wDXMlzB+4Z2BS7A64HTgB0ZLh46v5WfCpzZLjhax3AVL1W1Lsm7gMvbdu+cuKBIkqQtYZxX4X6eqc9FfnKaOicBJ01Rvho4aIryB4FXb6StlcDKmfZXkqTN4Z2IJEnqYIBKktTBAJUkqYMBKklSBwNUkqQOBqgkSR0MUEmSOhigkiR1MEAlSepggEqS1MEAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDgaoJEkdDFBJkjoYoJIkdTBAJUnqYIBKktTBAJUkqYMBKklSBwNUkqQOBqgkSR0MUEmSOhigkiR1MEAlSepggEqS1MEAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDgaoJEkdDFBJkjoYoJIkdTBAJUnqYIBKktTBAJUkqYMBKklSBwNUkqQOBqgkSR0MUEmSOhigkiR1MEAlSepggEqS1MEAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6jC1Ak+yT5LNJrktyTZI3t/Ldk6xKckP7udtInXckWZPk+iSHj5Q/J8nVbd37kqSV75Dk7FZ+aZIlI3VWtH3ckGTFuI5TkrRtGucIdD3wtqr6YeB5wBuSHAAcD1xYVfsDF7bntHXLgQOBI4D3J9mutfUB4Dhg//Y4opUfC9xdVfsBJwPvaW3tDpwAPBdYBpwwGtSSJD1aYwvQqrqtqr7clu8HrgP2Bo4CTm+bnQ4c3ZaPAj5SVQ9V1Y3AGmBZkicDu1TVJVVVwBmT6ky0dS5waBudHg6sqqp1VXU3sIrvhq4kSY/arJwDbVOrzwYuBfaqqttgCFngSW2zvYGbR6rd0sr2bsuTyzeoU1XrgXuBPaZpS5KkLWLsAZpkJ+CjwFuq6r7pNp2irKYp760z2rfjkqxOsnrt2rXTdE2SpA2NNUCTPJYhPP+mqv62Fd/RpmVpP+9s5bcA+4xUXwzc2soXT1G+QZ0k2wO7AuumaWsDVXVKVS2tqqWLFi3qPUxJ0jZonFfhBjgVuK6q/nhk1XnAxFWxK4CPjZQvb1fW7stwsdBlbZr3/iTPa20eM6nORFuvAi5q50kvAA5Lslu7eOiwViZJ0hax/RjbfiHwi8DVSa5sZb8LvBs4J8mxwNeBVwNU1TVJzgGuZbiC9w1V9XCr93rgNGBH4Pz2gCGgz0yyhmHkuby1tS7Ju4DL23bvrKp14zpQSdK2Z2wBWlWfZ+pzkQCHbqTOScBJU5SvBg6aovxBWgBPsW4lsHKm/ZUkaXN4JyJJkjoYoJIkdTBAJUnqYIBKktTBAJUkqYMBKklSBwNUkqQOBqgkSR0MUEmSOhigkiR1MEAlSepggEqS1MEAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDgaoJEkdDFBJkjoYoJIkdTBAJUnqYIBKktTBAJUkqYMBKklSBwNUkqQOBqgkSR0MUEmSOhigkiR1MEAlSepggEqS1MEAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDgaoJEkdDFBJkjoYoJIkdTBAJUnqYIBKktTBAJUkqYMBKklSBwNUkqQOBqgkSR0MUEmSOhigkiR1MEAlSepggEqS1MEAlSSpgwEqSVIHA1SSpA5jC9AkK5PcmeQrI2UnJvlGkivb48iRde9IsibJ9UkOHyl/TpKr27r3JUkr3yHJ2a380iRLRuqsSHJDe6wY1zFKkrZd4xyBngYcMUX5yVV1cHt8EiDJAcBy4MBW5/1JtmvbfwA4Dti/PSbaPBa4u6r2A04G3tPa2h04AXgusAw4IcluW/7wJEnbsrEFaFX9A7BuhpsfBXykqh6qqhuBNcCyJE8GdqmqS6qqgDOAo0fqnN6WzwUObaPTw4FVVbWuqu4GVjF1kEuS1G0uzoG+MclVbYp3YmS4N3DzyDa3tLK92/Lk8g3qVNV64F5gj2nakiRpi5ntAP0A8HTgYOA24I9aeabYtqYp762zgSTHJVmdZPXatWun67ckSRuY1QCtqjuq6uGqegT4IMM5ShhGifuMbLoYuLWVL56ifIM6SbYHdmWYMt5YW1P155SqWlpVSxctWvRoDk2StI3ZZIAmec9MymaindOc8Epg4grd84Dl7crafRkuFrqsqm4D7k/yvHZ+8xjgYyN1Jq6wfRVwUTtPegFwWJLd2hTxYa1MkqQtZvsZbPOTwNsnlf3UFGUbSPJh4BBgzyS3MFwZe0iSgxmmVG8Cfg2gqq5Jcg5wLbAeeENVPdyaej3DFb07Aue3B8CpwJlJ1jCMPJe3ttYleRdwedvunVU104uZJEmakY0GaJLXA78O/ECSq0ZW7Qx8YVMNV9Vrpyg+dZrtTwJOmqJ8NXDQFOUPAq/eSFsrgZWb6qMkSb2mG4GexTDa+wPg+JHy+x3RSZK2ddMF6HbAfcAbJq9IsrshKknalk0XoFew8a+MFPADY+mRJEkLwEYDtKr2nc2OSJK0kMzkKlyS7A08bXT7dqs+SZK2SZsM0Padz9cwfMVk4qslBRigkqRt1kxGoEcDP1hVD427M5IkLRQzuZXf14DHjrsjkiQtJNPdSOF/M0zVPgBcmeRC4D9GoVX1pvF3T5Kk+Wm6KdzV7ecVDPedlSRJzXRfYzl9Y+skSdrWzeQq3P0Zbud3APD4ifKq8kYKkqRt1kYvIkry+bb41wx/CHs98GLgDODM8XdNkqT5a7qrcI9sP3esqguBVNW/VtWJwEvG3jNJkuax6QL0rPbzofbHrG9I8sYkrwSeNP6uSZI0f200QKvq5W3xrcBOwJuA5wC/AKwYf9ckSZq/ZnInoscBD1TV/cAvAyT50bH2SpKkeW4mdyK6ALgoyV4jZX81pv5IkrQgzCRArwf+F3Bxkhe0ssl/H1SSpG3KTKZwq6o+nuR64OwkK/nuH9qWJGmbNJMRaACq6gbgRcCPAz8yzk5JkjTfbXIEWlXPHll+APi5JE8da68kSZrnZjIC/R5V9fUt3RFJkhaSrgCVJGlbt8kATbLvTMokSdqWzGQE+tEpys7d0h2RJGkh2ehFREl+CDgQ2DXJz4ys2oWRP2smSdK2aLqrcH8QeDnwROCnR8rvB143zk5JkjTfbTRAq+pjST4OvL2q/ucs9kmSpHlv2nOgVfUw8JOz1BdJkhaMmdzK74tJ/gw4G/j2RGFVfXlsvZIkaZ6bSYBO3ED+nSNlBbxky3dHkqSFYSa38nvxbHREkqSFZCY3UtgryalJzm/PD0hy7Pi7JknS/DWTGymcxvBHtZ/Snv8z8JZxdUiSpIVgJgG6Z1WdAzwCUFXrgYfH2itJkua5mQTot5PsQfsj2kmeB9w71l5JkjTPzeQq3LcB5wFPT/IFYBHwqrH2SpKkeW66e+G+BfgC8I/ATzDc2i/A9VX177PTPUmS5qfppnAXA38K3Al8BvjPwNOAnWehX5IkzWvT3Qv3twCSPA5YynBDhV8BPpjknqo6YHa6KEnS/DOTc6A7MvwJs13b41bg6nF2SpKk+W66c6CnMPw90PuBS4EvAn9cVXfPUt8kSZq3pjsH+lRgB+B24BvALcA9s9EpSZLmu+nOgR6RJAyj0BcwfJ3loCTrgEuq6oRZ6qMkSfPOtOdAq6qAryS5h+HmCfcCLweWAQaoJGmbNd050DcxjDxfCPw7w3dCLwFW4kVEkqRt3HQj0CXAucBbq+q22emOJEkLw3TnQH9zNjsiSdJCMpObyUuSpEkMUEmSOhigkiR1MEAlSepggEqS1MEAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKnD2AI0ycokdyb5ykjZ7klWJbmh/dxtZN07kqxJcn2Sw0fKn5Pk6rbufUnSyndIcnYrvzTJkpE6K9o+bkiyYlzHKEnado1zBHoacMSksuOBC6tqf+DC9pwkBwDLgQNbnfcn2a7V+QBwHLB/e0y0eSxwd1XtB5wMvKe1tTtwAvBcYBlwwmhQS5K0JYwtQKvqH4B1k4qPAk5vy6cDR4+Uf6SqHqqqG4E1wLIkTwZ2qapLqqqAMybVmWjrXODQNjo9HFhVVeuq6m5gFd8b5JIkPSqzfQ50r6q6DaD9fFIr3xu4eWS7W1rZ3m15cvkGdapqPXAvsMc0bUmStMXMl4uIMkVZTVPeW2fDnSbHJVmdZPXatWtn1FFJkmD2A/SONi1L+3lnK78F2Gdku8XAra188RTlG9RJsj2wK8OU8cba+h5VdUpVLa2qpYsWLXoUhyVJ2tbMdoCeB0xcFbsC+NhI+fJ2Ze2+DBcLXdamee9P8rx2fvOYSXUm2noVcFE7T3oBcFiS3drFQ4e1MkmStpjtx9Vwkg8DhwB7JrmF4crYdwPnJDkW+DrwaoCquibJOcC1wHrgDVX1cGvq9QxX9O4InN8eAKcCZyZZwzDyXN7aWpfkXcDlbbt3VtXki5kkSXpUxhagVfXajaw6dCPbnwScNEX5auCgKcofpAXwFOtWAitn3FlJkjbTfLmISJKkBcUAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDgaoJEkdDFBJkjoYoJIkdTBAJUnqYIBKktTBAJUkqYMBKklSBwNUkqQOBqgkSR0MUEmSOhigkiR1MEAlSepggEqS1MEAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDgaoJEkdDFBJkjoYoJIkdTBAJUnqYIBKktTBAJUkqYMBKklSBwNUkqQOBqgkSR0MUEmSOhigkiR1MEAlSepggEqS1MEAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKnD9nPdAWnUkuM/Mddd2Kib3v2yue6CpHnEEagkSR0MUEmSOhigkiR1MEAlSepggEqS1GFOAjTJTUmuTnJlktWtbPckq5Lc0H7uNrL9O5KsSXJ9ksNHyp/T2lmT5H1J0sp3SHJ2K780yZLZPkZJ0tZtLkegL66qg6tqaXt+PHBhVe0PXNiek+QAYDlwIHAE8P4k27U6HwCOA/ZvjyNa+bHA3VW1H3Ay8J5ZOB5J0jZkPk3hHgWc3pZPB44eKf9IVT1UVTcCa4BlSZ4M7FJVl1RVAWdMqjPR1rnAoROjU0mStoS5CtACPp3kiiTHtbK9quo2gPbzSa18b+Dmkbq3tLK92/Lk8g3qVNV64F5gj8mdSHJcktVJVq9du3aLHJgkadswV3ciemFV3ZrkScCqJF+dZtupRo41Tfl0dTYsqDoFOAVg6dKl37NekqSNmZMRaFXd2n7eCfwdsAy4o03L0n7e2Ta/BdhnpPpi4NZWvniK8g3qJNke2BVYN45jkSRtm2Y9QJM8IcnOE8vAYcBXgPOAFW2zFcDH2vJ5wPJ2Ze2+DBcLXdamee9P8rx2fvOYSXUm2noVcFE7TypJ0hYxF1O4ewF/167p2R44q6o+leRy4JwkxwJfB14NUFXXJDkHuBZYD7yhqh5ubb0eOA3YETi/PQBOBc5MsoZh5Ll8Ng5MkrTtmPUAraqvAc+aovybwKEbqXMScNIU5auBg6Yof5AWwJIkjcN8+hqLJEkLhgEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDgaoJEkdDFBJkjoYoJIkdZiLvwcqaQtbcvwn5roLG3XTu182112QxsIRqCRJHQxQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDt5IQdI2yxtQ6NFwBCpJUgcDVJKkDgaoJEkdDFBJkjoYoJIkdTBAJUnqYIBKktTBAJUkqYMBKklSBwNUkqQOBqgkSR0MUEmSOngzeUnSZpnPN+GH2bsRvyNQSZI6GKCSJHUwQCVJ6mCASpLUwQCVJKmDASpJUgcDVJKkDgaoJEkdDFBJkjoYoJIkdTBAJUnqYIBKktTBAJUkqYMBKklSBwNUkqQOBqgkSR0MUEmSOhigkiR1MEAlSepggEqS1MEAlSSpgwEqSVIHA1SSpA4GqCRJHQxQSZI6GKCSJHXYqgM0yRFJrk+yJsnxc90fSdLWY6sN0CTbAX8O/BRwAPDaJAfMba8kSVuLrTZAgWXAmqr6WlX9G/AR4Kg57pMkaSuRqprrPoxFklcBR1TVr7bnvwg8t6reOLLNccBx7ekPAtfPekdnbk/grrnuxALk69bH162Pr1uf+fy6Pa2qFk21YvvZ7sksyhRlG/y2UFWnAKfMTncenSSrq2rpXPdjofF16+Pr1sfXrc9Cfd225incW4B9Rp4vBm6do75IkrYyW3OAXg7sn2TfJI8DlgPnzXGfJElbia12Creq1id5I3ABsB2wsqqumeNuPRoLYqp5HvJ16+Pr1sfXrc+CfN222ouIJEkap615CleSpLExQCVJ6mCASpLUwQCd55K8KMlvJjlsrvuy0CQ5Y677oK1bkmVJfqwtH9D+rx451/2a75L8UJJDk+w0qfyIuepTDy8immeSXFZVy9ry64A3AH8HHAb8fVW9ey77N18lmfwVpQAvBi4CqKpXzHqntgJJfrmq/nqu+zEfJTmB4V7b2wOrgOcCFwMvBS6oqpPmrnfzV5I3MXyuXQccDIjXdmMAAAPPSURBVLy5qj7W1n25qn50Lvu3OQzQeSbJP1bVs9vy5cCRVbU2yROAL1XVM+e2h/NTki8D1wJ/xXDHqQAfZvj+L1X1ubnr3cKV5OtV9dS57sd8lORqhgDYAbgdWFxV9yXZEbi0qn5kTjs4T7XX7flV9a0kS4BzgTOr6k9HP/8Wgq32e6AL2GOS7MYwvZ6qWgtQVd9Osn5uuzavLQXeDPxX4Ler6sok3zE4Ny3JVRtbBew1m31ZYNZX1cPAA0n+paruA6iq7yR5ZI77Np9tV1XfAqiqm5IcApyb5GlMfQvWecsAnX92Ba5geCNVku+vqtvbuYIF9eaaTVX1CHBykv/Tft6B7++Z2gs4HLh7UnmAL85+dxaMf0vyfVX1APCcicIkuwIG6MbdnuTgqroSoI1EXw6sBBbUDJsfMPNMVS3ZyKpHgFfOYlcWpKq6BXh1kpcB9811fxaIjwM7TXygjUpy8ex3Z8H48ap6CP7jF7gJjwVWzE2XFoRjgA1m06pqPXBMkr+cmy718RyoJEkd/BqLJEkdDFBJkjoYoNICl+ThJFeOPI7fQu3+UpI/28w670zy0i2xf2m+8yIiaeH7TlUdPN0GSbZrX7kYq6r6vXHvQ5ovHIFKW6kkNyX5vSSfZ7gy+cgkX03y+STvS/Lxtt0TkqxMcnmSf0xy1Egz+yT5VJLr2513SLIkyXVJPpjkmiSfbjcPIMlpSV7Vlt+d5NokVyV572wfvzRujkClhW/HJKNfQfmDqjq7LT9YVS9K8njgBoavXtyY5MMj2/9X4KKq+pUkTwQuS/KZtm4ZcBDwAHB5kk8AdwH7A6+tqtclOQf4WeBDEw0m2Z3ha1c/VFXV2pW2Ko5ApYXvO1V18Mjj7JF1E8s/BHytqm5sz0cD9DDg+BbCFwOPByZu37eqqr5ZVd8B/hZ4USu/ceR7o1cASyb16T7gQeCvkvwMQwBLWxUDVNq6fbv9nO4uVgF+diSAn1pV17V1k78oPvH8oZGyh5k0m9W+GL8M+ChwNPCpns5L85kBKm0bvgr8QLt5N8BrRtZdAPxGkgAkGb2Z908m2b2d4zwa+MJMdtZuPblrVX0SeAvDTdelrYrnQKWFb/I50E9V1QZfZWk3OP914FNJ7gIuG1n9LuBPgKtaiN4EvLyt+zxwJrAfcFZVrR4J4ensDHysnXsN8NbNPippnvNWftI2IslO7cbdAf4cuKGqTp7rfkkLlVO40rbjdW2keg3DX/1ZUDfuluYbR6CSJHVwBCpJUgcDVJKkDgaoJEkdDFBJkjoYoJIkdTBAJUnq8P8Bflv44+NLZAkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax:object = df['Score'].value_counts().plot(kind='bar', figsize=(7,7))\n",
    "fig:object = ax.get_figure()\n",
    "ax.set_title(\"Amazon's Fine Food Reviews Dataset\")\n",
    "ax.set_xlabel('Ergebnis')\n",
    "ax.set_ylabel('Wert zählt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29eaf30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eine knappe Zusammenfassung des DataFrame ist:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 393919 entries, 1 to 568454\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   ProductId               393919 non-null  object\n",
      " 1   UserId                  393919 non-null  object\n",
      " 2   ProfileName             393919 non-null  object\n",
      " 3   HelpfulnessNumerator    393919 non-null  int64 \n",
      " 4   HelpfulnessDenominator  393919 non-null  int64 \n",
      " 5   Score                   393919 non-null  int64 \n",
      " 6   Time                    393919 non-null  int64 \n",
      " 7   Summary                 393919 non-null  object\n",
      " 8   Text                    393919 non-null  object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 30.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print('Eine knappe Zusammenfassung des DataFrame ist:')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900d591",
   "metadata": {},
   "source": [
    "Wir wollen weitere Informationen über die Bewertungen erfahren, wie z. B.: <br>\n",
    "Längste, kürzeste Bewertung <br>\n",
    "Längste, kürzeste Zusammenfassung <br>\n",
    "Die Person mit den meisten Bewertungen <br>\n",
    "Diese Daten helfen uns, einen besseren Überblick über den Datensatz zu bekommen, mit dem wir arbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1a5e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die längste geschriebene Rezension ist: 21409\n",
      "Die kürzeste geschriebene Rezension ist: 12\n",
      "Die längste Zusammenfassung lautet: 128\n",
      "Die kürzeste Zusammenfassung lautet: 1\n",
      "Der Name des Profils mit den meisten Bewertungen lautet:\n",
      "0    Gary Peterson\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f'Die längste geschriebene Rezension ist: {df.Text.map(lambda x: len(x)).max()}')\n",
    "print(f'Die kürzeste geschriebene Rezension ist: {df.Text.map(lambda x: len(x)).min()}')\n",
    "print(f'Die längste Zusammenfassung lautet: {df.Summary.map(lambda x: len(x)).max()}')\n",
    "print(f'Die kürzeste Zusammenfassung lautet: {df.Summary.map(lambda x: len(x)).min()}')\n",
    "print(f'Der Name des Profils mit den meisten Bewertungen lautet:')\n",
    "print(df.ProfileName.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06fe6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions:Dict[str,str] = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d674781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text:str, remove_stopwords:bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Unerwünschte Zeichen und Stoppwörter entfernen und den Text so formatieren, dass weniger Nullen in den Text eingebettet werden\n",
    "    param text: der Text, der formatiert werden soll\n",
    "    param remove_stopwords: \n",
    "    Rückgabe:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Konvertiert Wörter so, dass sie nur kleine Buchstaben haben.\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Ersetzt Abkürzungen durch ihre Langform\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text:List[str] = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Wörter formatieren und unerwünschte Zeichen wie Anführungszeichen, Punkte usw. entfernen.\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # Unnötige Wörter entfernen\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops:set = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    # Tokenisierung des Textes: Sätze in Wörter unterteilen\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1966e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_Cleaned'] = list(map(clean_text, df.Text))\n",
    "def lemmatized_words(text):\n",
    "    lemm:nltk.stem.wordnet.WordNetLemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    df['Lemmatized_text'] = list(map(lambda word:list(map(lemm.lemmatize, word)),df.Text_Cleaned))\n",
    "\n",
    "lemmatized_words(df.Text_Cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e209f070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Lemmatized_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "      <td>[confection, around, century, light, pillowy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductId          UserId                      ProfileName  \\\n",
       "Id                                                                \n",
       "1   B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "2   B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "3   B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "4   B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "5   B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "    HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "Id                                                                    \n",
       "1                      1                       1      5  1303862400   \n",
       "2                      0                       0      1  1346976000   \n",
       "3                      1                       1      4  1219017600   \n",
       "4                      3                       3      2  1307923200   \n",
       "5                      0                       0      5  1350777600   \n",
       "\n",
       "                  Summary                                               Text  \\\n",
       "Id                                                                             \n",
       "1   Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "2       Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "3   \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "4          Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "5             Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                         Text_Cleaned  \\\n",
       "Id                                                      \n",
       "1   [bought, several, vitality, canned, dog, food,...   \n",
       "2   [product, arrived, labeled, jumbo, salted, pea...   \n",
       "3   [confection, around, centuries, light, pillowy...   \n",
       "4   [looking, secret, ingredient, robitussin, beli...   \n",
       "5   [great, taffy, great, price, wide, assortment,...   \n",
       "\n",
       "                                      Lemmatized_text  \n",
       "Id                                                     \n",
       "1   [bought, several, vitality, canned, dog, food,...  \n",
       "2   [product, arrived, labeled, jumbo, salted, pea...  \n",
       "3   [confection, around, century, light, pillowy, ...  \n",
       "4   [looking, secret, ingredient, robitussin, beli...  \n",
       "5   [great, taffy, great, price, wide, assortment,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc40e87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Lemmatized_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178880</th>\n",
       "      <td>4</td>\n",
       "      <td>I use this stuff all the time in coffee, tea, and baking. There a bit of an aftertaste, but it's not as bitter as Stevia and I only really notice it when I use it make something like maple syrup. I'm also not convinced that the conversion is 2 drops = 2 tsp. I think you need a little more than two drops, but you're still getting a ton of sweetener in a tiny bottle. Overall, I'm pretty happy with it.</td>\n",
       "      <td>[use, stuff, time, coffee, tea, baking, bit, aftertaste, bitter, stevia, really, notice, use, make, something, like, maple, syrup, also, convinced, conversion, 2, drops, 2, tsp, think, need, little, two, drops, still, getting, ton, sweetener, tiny, bottle, overall, pretty, happy]</td>\n",
       "      <td>[use, stuff, time, coffee, tea, baking, bit, aftertaste, bitter, stevia, really, notice, use, make, something, like, maple, syrup, also, convinced, conversion, 2, drop, 2, tsp, think, need, little, two, drop, still, getting, ton, sweetener, tiny, bottle, overall, pretty, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296295</th>\n",
       "      <td>5</td>\n",
       "      <td>I put this **** on everything. Well all meats that I grill/smoke anyway.  I first ran into this product while living in Austin, TX over 10 years ago and have been using it since.  For whatever reason I decided to check Amazon as I usually order directly from Bolner's site. What do you know?  It's not only on Amazon, but it is a Prime eligible product as well. For anyone who may read this review, buy the smaller container of this stuff to give it a try if you are not 100% sure, and I bet that...</td>\n",
       "      <td>[put, everything, well, meats, grill, smoke, anyway, first, ran, product, living, austin, tx, 10, years, ago, using, since, whatever, reason, decided, check, amazon, usually, order, directly, bolner, site, know, amazon, prime, eligible, product, well, anyone, may, read, review, buy, smaller, container, stuff, give, try, 100, sure, bet, next, order, buy, big, container]</td>\n",
       "      <td>[put, everything, well, meat, grill, smoke, anyway, first, ran, product, living, austin, tx, 10, year, ago, using, since, whatever, reason, decided, check, amazon, usually, order, directly, bolner, site, know, amazon, prime, eligible, product, well, anyone, may, read, review, buy, smaller, container, stuff, give, try, 100, sure, bet, next, order, buy, big, container]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173021</th>\n",
       "      <td>4</td>\n",
       "      <td>I've tried all of the Maesri curries and haven't found one that I don't like. They really can't be beat for convenience, price, and taste. But be warned, this one is HOT! (It made my girlfriend cry) If you don't like the spice, either add some coconut milk or try a different one all together.</td>\n",
       "      <td>[tried, maesri, curries, found, one, like, really, cannot, beat, convenience, price, taste, warned, one, hot, made, girlfriend, cry, like, spice, either, add, coconut, milk, try, different, one, together]</td>\n",
       "      <td>[tried, maesri, curry, found, one, like, really, cannot, beat, convenience, price, taste, warned, one, hot, made, girlfriend, cry, like, spice, either, add, coconut, milk, try, different, one, together]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246225</th>\n",
       "      <td>5</td>\n",
       "      <td>It's really stronge but if you combine it with the right foods it taste excellent.. Don't laugh I've found it taste very good with rice..</td>\n",
       "      <td>[really, stronge, combine, right, foods, taste, excellent, laugh, found, taste, good, rice]</td>\n",
       "      <td>[really, stronge, combine, right, food, taste, excellent, laugh, found, taste, good, rice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15385</th>\n",
       "      <td>5</td>\n",
       "      <td>As a young girl this was one of my favorite treats! As the years passed it became unavailable. I am so glad I was able to find it here on Amazon. My family and I can once again enjoy the great taste of Tahitian Treat!!!</td>\n",
       "      <td>[young, girl, one, favorite, treats, years, passed, became, unavailable, glad, able, find, amazon, family, enjoy, great, taste, tahitian, treat]</td>\n",
       "      <td>[young, girl, one, favorite, treat, year, passed, became, unavailable, glad, able, find, amazon, family, enjoy, great, taste, tahitian, treat]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score  \\\n",
       "Id              \n",
       "178880      4   \n",
       "296295      5   \n",
       "173021      4   \n",
       "246225      5   \n",
       "15385       5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Text  \\\n",
       "Id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "178880                                                                                                   I use this stuff all the time in coffee, tea, and baking. There a bit of an aftertaste, but it's not as bitter as Stevia and I only really notice it when I use it make something like maple syrup. I'm also not convinced that the conversion is 2 drops = 2 tsp. I think you need a little more than two drops, but you're still getting a ton of sweetener in a tiny bottle. Overall, I'm pretty happy with it.   \n",
       "296295  I put this **** on everything. Well all meats that I grill/smoke anyway.  I first ran into this product while living in Austin, TX over 10 years ago and have been using it since.  For whatever reason I decided to check Amazon as I usually order directly from Bolner's site. What do you know?  It's not only on Amazon, but it is a Prime eligible product as well. For anyone who may read this review, buy the smaller container of this stuff to give it a try if you are not 100% sure, and I bet that...   \n",
       "173021                                                                                                                                                                                                                I've tried all of the Maesri curries and haven't found one that I don't like. They really can't be beat for convenience, price, and taste. But be warned, this one is HOT! (It made my girlfriend cry) If you don't like the spice, either add some coconut milk or try a different one all together.   \n",
       "246225                                                                                                                                                                                                                                                                                                                                                                            It's really stronge but if you combine it with the right foods it taste excellent.. Don't laugh I've found it taste very good with rice..   \n",
       "15385                                                                                                                                                                                                                                                                                           As a young girl this was one of my favorite treats! As the years passed it became unavailable. I am so glad I was able to find it here on Amazon. My family and I can once again enjoy the great taste of Tahitian Treat!!!   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                               Text_Cleaned  \\\n",
       "Id                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "178880                                                                                             [use, stuff, time, coffee, tea, baking, bit, aftertaste, bitter, stevia, really, notice, use, make, something, like, maple, syrup, also, convinced, conversion, 2, drops, 2, tsp, think, need, little, two, drops, still, getting, ton, sweetener, tiny, bottle, overall, pretty, happy]   \n",
       "296295  [put, everything, well, meats, grill, smoke, anyway, first, ran, product, living, austin, tx, 10, years, ago, using, since, whatever, reason, decided, check, amazon, usually, order, directly, bolner, site, know, amazon, prime, eligible, product, well, anyone, may, read, review, buy, smaller, container, stuff, give, try, 100, sure, bet, next, order, buy, big, container]   \n",
       "173021                                                                                                                                                                         [tried, maesri, curries, found, one, like, really, cannot, beat, convenience, price, taste, warned, one, hot, made, girlfriend, cry, like, spice, either, add, coconut, milk, try, different, one, together]   \n",
       "246225                                                                                                                                                                                                                                                                                          [really, stronge, combine, right, foods, taste, excellent, laugh, found, taste, good, rice]   \n",
       "15385                                                                                                                                                                                                                                      [young, girl, one, favorite, treats, years, passed, became, unavailable, glad, able, find, amazon, family, enjoy, great, taste, tahitian, treat]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                          Lemmatized_text  \n",
       "Id                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "178880                                                                                             [use, stuff, time, coffee, tea, baking, bit, aftertaste, bitter, stevia, really, notice, use, make, something, like, maple, syrup, also, convinced, conversion, 2, drop, 2, tsp, think, need, little, two, drop, still, getting, ton, sweetener, tiny, bottle, overall, pretty, happy]  \n",
       "296295  [put, everything, well, meat, grill, smoke, anyway, first, ran, product, living, austin, tx, 10, year, ago, using, since, whatever, reason, decided, check, amazon, usually, order, directly, bolner, site, know, amazon, prime, eligible, product, well, anyone, may, read, review, buy, smaller, container, stuff, give, try, 100, sure, bet, next, order, buy, big, container]  \n",
       "173021                                                                                                                                                                         [tried, maesri, curry, found, one, like, really, cannot, beat, convenience, price, taste, warned, one, hot, made, girlfriend, cry, like, spice, either, add, coconut, milk, try, different, one, together]  \n",
       "246225                                                                                                                                                                                                                                                                                         [really, stronge, combine, right, food, taste, excellent, laugh, found, taste, good, rice]  \n",
       "15385                                                                                                                                                                                                                                      [young, girl, one, favorite, treat, year, passed, became, unavailable, glad, able, find, amazon, family, enjoy, great, taste, tahitian, treat]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 500)\n",
    "df[['Score', 'Text', 'Text_Cleaned', 'Lemmatized_text']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58420fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der bereinigte Text hat: 110422 Wörter\n"
     ]
    }
   ],
   "source": [
    "bow_converter:sklearn.feature_extraction.text.CountVectorizer = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=[1,1], lowercase=False)\n",
    "x:scipy.sparse.csr.csr_matrix = bow_converter.fit_transform(df['Text_Cleaned'])\n",
    "\n",
    "words:List[str] = bow_converter.get_feature_names()\n",
    "print(f'Der bereinigte Text hat: {len(words)} Wörter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "550b8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow:sklearn.feature_extraction.text.CountVectorizer = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=[1,1], lowercase=False)\n",
    "X1:scipy.sparse.csr.csr_matrix = bow.fit_transform(df['Text_Cleaned'])\n",
    "y1:np.ndarray = df['Score']\n",
    "    \n",
    "X1 = X1[:1000]\n",
    "y1 = y1[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f8d3875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg:sklearn.linear_model._base.LinearRegression = LinearRegression()\n",
    "ridge:sklearn.linear_model._ridge.Ridge = Ridge(alpha=1.0)\n",
    "lasso:sklearn.linear_model._coordinate_descent.Lasso = Lasso(alpha=1.0)\n",
    "elastic_net:sklearn.linear_model._coordinate_descent.ElasticNet = ElasticNet(random_state=0)\n",
    "\n",
    "linear_reg.fit(X1, y1)\n",
    "ridge.fit(X1, y1)\n",
    "lasso.fit(X1, y1)\n",
    "elastic_net.fit(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge:sklearn.linear_model._ridge.Ridge = Ridge(alpha=1.0)\n",
    "lasso:sklearn.linear_model._coordinate_descent.Lasso = Lasso(alpha=1.0)\n",
    "elastic_net:sklearn.linear_model._coordinate_descent.ElasticNet = ElasticNet(random_state=0)\n",
    "\n",
    "ridge.fit(X1, y1)\n",
    "lasso.fit(X1, y1)\n",
    "elastic_net.fit(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97dd4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_params() -> Dict[str,List[bool]]:\n",
    "    \"\"\"\n",
    "    Erzeugt ein Wörterbuch mit den Namen der Parameter als Schlüssel und als Werte,\n",
    "    Listen mit den möglichen Werten; für lineare Regression\n",
    "    return: das Wörterbuch\n",
    "    \"\"\"\n",
    "    copy_X:List[bool] = [True,False]\n",
    "    fit_intercept:List[bool] = [True,False]\n",
    "    return dict(copy_X=copy_X, fit_intercept=fit_intercept)\n",
    "\n",
    "def lasso_ridge_elastic_params() -> Dict[str,List[Union[float,bool]]]:\n",
    "    \"\"\"\n",
    "    Erzeugt ein Wörterbuch mit den Namen der Parameter als Schlüssel und als Werte,\n",
    "    Listen mit den möglichen Werten; für Lasso, Ridge und Elastic Net\n",
    "    return: das Wörterbuch\n",
    "    \"\"\"\n",
    "    alpha:List[float] = [1.0,1.1,1.2,1.3,1.4,1.5]\n",
    "    fit_intercept:List[bool] = [True,False]\n",
    "    return dict(alpha=alpha, fit_intercept=fit_intercept)\n",
    "\n",
    "def randomized_search(model:sklearn.linear_model, param_distributions:Dict[str,List[Union[float,bool]]], data:np.ndarray, target:np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet die optimalen Hyperparameterwerte für ein gewähltes Regressionsmodell für einen gegebenen Datensatz\n",
    "    param model: das Regressionsmodell\n",
    "    param param_distributions: Wörterbuch mit den Namen der Parameter als Wert der Schlüssel und einer Reihe von Werten\n",
    "    param date: das Datum des Datensatzes\n",
    "    param target: das Ziel des Datensatzes\n",
    "    \"\"\"\n",
    "    randomized_src:sklearn.model_selection.RandomizedSearchCV = RandomizedSearchCV(estimator = model, param_distributions=param_distributions, n_iter = 5, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "    randomized_src.fit(data, target)\n",
    "    return randomized_src\n",
    "\n",
    "def randomize_calculate(model:sklearn.linear_model, params:Dict[str,List[Union[float,bool]]], data:np.ndarray, target:np.ndarray, score_type:str, error_type:str) -> float:\n",
    "    \"\"\"\n",
    "    Meldet die mittleren Ergebnisse für eine der Fold-Links (train / test) mit RandomizedSearchCV\n",
    "    param model: das Regressionsmodell\n",
    "    param param_grid: Wörterbuch mit dem Namen der Parameter als Wert der Schlüssel und einer Reihe von Werten\n",
    "    param date: die Daten des Datensatzes\n",
    "    param target: das Ziel des Datensatzes\n",
    "    param score_type: der Typ der Punktzahl\n",
    "    param error_type: die Art des Fehlers\n",
    "    \"\"\"\n",
    "    rand_src:sklearn.model_selection.RandomizedSearchCV = randomized_search(model, params, data, target)\n",
    "    result:List[float] = cross_validate(rand_src, data, target, cv=5, return_train_score=True, scoring=error_type)\n",
    "    return result[score_type].mean()\n",
    "\n",
    "def get_errors_score(score_type: str, error_type: str, data:np.ndarray, target:np.ndarray) -> List[float]:\n",
    "    \"\"\"\n",
    "    Erstellt eine Liste aus den mittleren Ergebnissen für die Trainingsfalten sowie für die Testfalten,\n",
    "    für einen gegebenen Datensatz\n",
    "    param score_type: die Art des Ergebnisses\n",
    "    param error_type: Typ des Fehlers\n",
    "    param date: das Datum des Datensatzes\n",
    "    param target: das Ziel des Datensatzes\n",
    "    return: Liste der Durchschnittswerte\n",
    "    \"\"\"\n",
    "    column:List[float] = []\n",
    "    column.append(randomize_calculate(linear_reg, lin_reg_params(), data, target, score_type, error_type))\n",
    "    column.append(randomize_calculate(ridge, lasso_ridge_elastic_params(), data, target, score_type, error_type))  \n",
    "    column.append(randomize_calculate(lasso, lasso_ridge_elastic_params(), data, target, score_type, error_type))   \n",
    "    column.append(randomize_calculate(elastic_net, lasso_ridge_elastic_params(), data, target, score_type, error_type))   \n",
    "    return column\n",
    "\n",
    "def get_data_frame(data:np.ndarray, target:np.ndarray) -> Dict[str,List[Union[str,float]]]:\n",
    "    \"\"\"\n",
    "    Erzeugt ein Wörterbuch aus den Spalten der Ergebnisdurchschnitte für die Trainingsfalten,\n",
    "    sowie für die Testfalten, für einen bestimmten Datensatz\n",
    "    param date: die Daten des Datensatzes\n",
    "    param target: das Ziel des Datensatzes\n",
    "    return: das Wörterbuch\n",
    "    \"\"\"\n",
    "    test_neg_mean_absolute_error:List[float] = get_errors_score('test_score', 'neg_mean_absolute_error', data, target)    \n",
    "    test_neg_mean_squared_error:List[float] = get_errors_score('test_score', 'neg_mean_squared_error', data, target)\n",
    "    test_r2_error:List[float] = get_errors_score('test_score', 'r2', data, target)\n",
    "    train_neg_mean_absolute_error:List[float] = get_errors_score('train_score', 'neg_mean_absolute_error', data, target)\n",
    "    train_neg_mean_squared_error:List[float] = get_errors_score('train_score', 'neg_mean_squared_error', data, target)\n",
    "    train_r2_error:List[float] = get_errors_score('train_score', 'r2', data, target)\n",
    "\n",
    "    data_frame:Dict[str,List[Union[str,float]]] = {\n",
    "            'Model_name': ['Linear Regression', 'Ridge', 'Lasso', 'Elastic Net'],\n",
    "            'Search_strategy': ['RandomizedSearchCV', 'RandomizedSearchCV', 'RandomizedSearchCV','RandomizedSearchCV'],\n",
    "            'test_neg_mean_absolute_error': test_neg_mean_absolute_error,\n",
    "            'test_neg_mean_squared_error': test_neg_mean_squared_error,\n",
    "            'test_r2_error': test_r2_error,\n",
    "            'train_neg_mean_absolute_error': train_neg_mean_absolute_error,\n",
    "            'train_neg_mean_squared_error': train_neg_mean_squared_error,\n",
    "            'train_r2_error': train_r2_error,\n",
    "        }\n",
    "    return data_frame\n",
    "\n",
    "def get_positive_data_frame(data_frame: Dict[str,List[Union[str,float]]]) -> Dict[str,List[Union[str,float]]]:\n",
    "    \"\"\"\n",
    "    Erstellt ein Wörterbuch mit positiven Werten aus den Spalten, die sich aus den Durchschnittswerten der Ergebnisse\n",
    "    sowohl für die Trainings- als auch für die Testfalten für einen bestimmten Datensatz\n",
    "    param date: die Daten des Datensatzes\n",
    "    param target: das Ziel des Datensatzes\n",
    "    return: das Wörterbuch\n",
    "    \"\"\"\n",
    "    pos_data_frame:Dict[str,List[Union[str,float]]] = {}\n",
    "    lst:List[Union[str,float]] = []\n",
    "    for key in data_frame:\n",
    "        for value in data_frame[key]:\n",
    "            if isinstance(value, float):\n",
    "                lst.append(abs(value))\n",
    "            else:\n",
    "                lst.append(value)\n",
    "        pos_data_frame[key.replace(\"_neg\",\"\")] = lst\n",
    "        lst = []\n",
    "    return pos_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d287399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Search_strategy</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <th>train_r2_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>-1.345795</td>\n",
       "      <td>-3.650591</td>\n",
       "      <td>-1.135267</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-6.455055e-12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>-1.084225</td>\n",
       "      <td>-2.095031</td>\n",
       "      <td>-0.210580</td>\n",
       "      <td>-0.106435</td>\n",
       "      <td>-2.502891e-02</td>\n",
       "      <td>0.985062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>-1.055418</td>\n",
       "      <td>-1.761159</td>\n",
       "      <td>-0.010801</td>\n",
       "      <td>-1.053401</td>\n",
       "      <td>-1.753556e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>-1.055418</td>\n",
       "      <td>-1.761159</td>\n",
       "      <td>-0.010801</td>\n",
       "      <td>-1.053401</td>\n",
       "      <td>-1.753556e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model_name     Search_strategy  test_neg_mean_absolute_error  \\\n",
       "0  Linear Regression  RandomizedSearchCV                     -1.345795   \n",
       "1              Ridge  RandomizedSearchCV                     -1.084225   \n",
       "2              Lasso  RandomizedSearchCV                     -1.055418   \n",
       "3        Elastic Net  RandomizedSearchCV                     -1.055418   \n",
       "\n",
       "   test_neg_mean_squared_error  test_r2_error  train_neg_mean_absolute_error  \\\n",
       "0                    -3.650591      -1.135267                      -0.000002   \n",
       "1                    -2.095031      -0.210580                      -0.106435   \n",
       "2                    -1.761159      -0.010801                      -1.053401   \n",
       "3                    -1.761159      -0.010801                      -1.053401   \n",
       "\n",
       "   train_neg_mean_squared_error  train_r2_error  \n",
       "0                 -6.455055e-12        1.000000  \n",
       "1                 -2.502891e-02        0.985062  \n",
       "2                 -1.753556e+00        0.000000  \n",
       "3                 -1.753556e+00        0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_frame:Dict[str,List[Union[str,float]]] = get_data_frame(X1, y1)\n",
    "new_data_frame:pandas.core.frame.DataFrame = pd.DataFrame(data_frame)\n",
    "display(new_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0e88f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Search_strategy</th>\n",
       "      <th>test_mean_absolute_error</th>\n",
       "      <th>test_mean_squared_error</th>\n",
       "      <th>test_r2_error</th>\n",
       "      <th>train_mean_absolute_error</th>\n",
       "      <th>train_mean_squared_error</th>\n",
       "      <th>train_r2_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>1.345795</td>\n",
       "      <td>3.650591</td>\n",
       "      <td>1.135267</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.455055e-12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>1.084225</td>\n",
       "      <td>2.095031</td>\n",
       "      <td>0.210580</td>\n",
       "      <td>0.106435</td>\n",
       "      <td>2.502891e-02</td>\n",
       "      <td>0.985062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>1.055418</td>\n",
       "      <td>1.761159</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>1.053401</td>\n",
       "      <td>1.753556e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>1.055418</td>\n",
       "      <td>1.761159</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>1.053401</td>\n",
       "      <td>1.753556e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model_name     Search_strategy  test_mean_absolute_error  \\\n",
       "0  Linear Regression  RandomizedSearchCV                  1.345795   \n",
       "1              Ridge  RandomizedSearchCV                  1.084225   \n",
       "2              Lasso  RandomizedSearchCV                  1.055418   \n",
       "3        Elastic Net  RandomizedSearchCV                  1.055418   \n",
       "\n",
       "   test_mean_squared_error  test_r2_error  train_mean_absolute_error  \\\n",
       "0                 3.650591       1.135267                   0.000002   \n",
       "1                 2.095031       0.210580                   0.106435   \n",
       "2                 1.761159       0.010801                   1.053401   \n",
       "3                 1.761159       0.010801                   1.053401   \n",
       "\n",
       "   train_mean_squared_error  train_r2_error  \n",
       "0              6.455055e-12        1.000000  \n",
       "1              2.502891e-02        0.985062  \n",
       "2              1.753556e+00        0.000000  \n",
       "3              1.753556e+00        0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_data_frame:Dict[str,List[Union[str,float]]] = get_positive_data_frame(data_frame)\n",
    "pos_df:pandas.core.frame.DataFrame = pd.DataFrame(positive_data_frame)\n",
    "display(pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "560f433b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col2 {\n",
       "            background-color:  green;\n",
       "            : ;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col3 {\n",
       "            background-color:  green;\n",
       "            : ;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col4 {\n",
       "            background-color:  green;\n",
       "            : ;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col5 {\n",
       "            : ;\n",
       "            background-color:  red;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col6 {\n",
       "            : ;\n",
       "            background-color:  red;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col7 {\n",
       "            background-color:  green;\n",
       "            : ;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col2 {\n",
       "            : ;\n",
       "            background-color:  red;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col3 {\n",
       "            : ;\n",
       "            background-color:  red;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col4 {\n",
       "            : ;\n",
       "            background-color:  red;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col5 {\n",
       "            background-color:  green;\n",
       "            : ;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col6 {\n",
       "            background-color:  green;\n",
       "            : ;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col7 {\n",
       "            : ;\n",
       "            background-color:  red;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col2 {\n",
       "            : ;\n",
       "            background-color:  red;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col3 {\n",
       "            : ;\n",
       "            background-color:  red;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col4 {\n",
       "            : ;\n",
       "            background-color:  red;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col5 {\n",
       "            background-color:  green;\n",
       "            : ;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col6 {\n",
       "            background-color:  green;\n",
       "            : ;\n",
       "        }    #T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col7 {\n",
       "            : ;\n",
       "            background-color:  red;\n",
       "        }</style><table id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model_name</th>        <th class=\"col_heading level0 col1\" >Search_strategy</th>        <th class=\"col_heading level0 col2\" >test_mean_absolute_error</th>        <th class=\"col_heading level0 col3\" >test_mean_squared_error</th>        <th class=\"col_heading level0 col4\" >test_r2_error</th>        <th class=\"col_heading level0 col5\" >train_mean_absolute_error</th>        <th class=\"col_heading level0 col6\" >train_mean_squared_error</th>        <th class=\"col_heading level0 col7\" >train_r2_error</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col0\" class=\"data row0 col0\" >Linear Regression</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col1\" class=\"data row0 col1\" >RandomizedSearchCV</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col2\" class=\"data row0 col2\" >1.345795</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col3\" class=\"data row0 col3\" >3.650591</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col4\" class=\"data row0 col4\" >1.135267</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col5\" class=\"data row0 col5\" >0.000002</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col6\" class=\"data row0 col6\" >0.000000</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow0_col7\" class=\"data row0 col7\" >1.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow1_col0\" class=\"data row1 col0\" >Ridge</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow1_col1\" class=\"data row1 col1\" >RandomizedSearchCV</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow1_col2\" class=\"data row1 col2\" >1.084225</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow1_col3\" class=\"data row1 col3\" >2.095031</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow1_col4\" class=\"data row1 col4\" >0.210580</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow1_col5\" class=\"data row1 col5\" >0.106435</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow1_col6\" class=\"data row1 col6\" >0.025029</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow1_col7\" class=\"data row1 col7\" >0.985062</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col0\" class=\"data row2 col0\" >Lasso</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col1\" class=\"data row2 col1\" >RandomizedSearchCV</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col2\" class=\"data row2 col2\" >1.055418</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col3\" class=\"data row2 col3\" >1.761159</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col4\" class=\"data row2 col4\" >0.010801</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col5\" class=\"data row2 col5\" >1.053401</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col6\" class=\"data row2 col6\" >1.753556</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow2_col7\" class=\"data row2 col7\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col0\" class=\"data row3 col0\" >Elastic Net</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col1\" class=\"data row3 col1\" >RandomizedSearchCV</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col2\" class=\"data row3 col2\" >1.055418</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col3\" class=\"data row3 col3\" >1.761159</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col4\" class=\"data row3 col4\" >0.010801</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col5\" class=\"data row3 col5\" >1.053401</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col6\" class=\"data row3 col6\" >1.753556</td>\n",
       "                        <td id=\"T_a596066d_f19d_11ed_b253_4074e0e63f9drow3_col7\" class=\"data row3 col7\" >0.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f3cdd23c70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style:pandas.io.formats.style.Styler = pos_df.style.\\\n",
    "    highlight_max(color = 'green', axis = 0).\\\n",
    "    highlight_min(color = 'red', axis = 0)\n",
    "\n",
    "style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e673142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
